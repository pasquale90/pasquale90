# Hi there, welcome to my page! 👋

I’m a developer passionate about building audio applications with **C++** and **Python**, always open to interesting new initiatives! 🎶 💻 🎸 🖥️ 🎺 

✨ I’m currently building **VST plugins** with **C++** and **JUCE** alongside some talented folks 🔭, and in the process, I’m learning about **ONNX** and how to use **LibTorch** for model conversion in audio tools. 🌱 ✨

🚀 Feel free to check out my projects below! 👇

## 🏆 Featured Projects:

- **[Interactive Audio Visualizer](https://github.com/pasquale90/interactive-audio-visualizer)**: Bringing Sound to Life with Interactive Real-Time Audio-Visual Experience 🎶🎚️


This project develops an innovative interactive tool designed to offer a real-time audiovisual experience for users. The envisioned objective of IAV is to provide individuals with limited mobility or minimal musical background an accessible way to engage with positive musical stimuli, using simple actions like hand movements, to inspire and motivate them to participate in creative expression.

<h1 align="center">

  <a href="https://github.com/pasquale90/interactive-audio-visualizer"><img src="https://github.com/pasquale90/interactive-audio-visualizer/blob/main/files/imgs/iav.gif" width="500"></a>

</h1>

- **[Pi-Loop-Console](https://github.com/pasquale90/pi-loop-console)**: A linux based audio looper written in C++. 🎸 🎺 🪕 🎻 🎹 

Pi-Loop is a real-time audio looper application that enables users to create interactive musical sessions. One may use an external audio interface to connect a microphone and an instrument or to use the integrated sound card to test it. <br><br>

<h1 align="center">

  <a href="https://github.com/pasquale90/pi-loop-console"><img src="https://github.com/pasquale90/pi-loop-console/blob/main/files/imgs/piloop-demoRPI.gif" width="500"></a>

</h1>


- **[My diploma thesis](https://github.com/pasquale90/mthesis)**: Audio signal classification using deep learning algorithms.

In this thesis we compared the performance of multiple feature parameters for environmental sound classification problems by developing multiple evaluating models. Specifically, as audio representation of two different datasets, we used raw waveforms, log-mel spectrograms and short-time Fourier transforms. Finally we set four different experiments and each one of them was divided in two discrete audio representation modes. For their evaluation and also for comparability purposes we developed hybrid CNN models. Along with comparing each mode within each experiment, we also compared the performances achieved by using each different dataset through inspecting and examining the factors of structure, the technical features and various prospects of the initial data distribution, respectively for each dataset. The nature of this research additionally enabled us to seek for potential environmental class-conditional audio features.

<h1 align="center">

  <a href="https://github.com/pasquale90/mthesis"><img src="https://github.com/pasquale90/mthesis/raw/master/arch/method.png" width="500"></a>

</h1>

- **[The SMOD Project](https://github.com/pasquale90/the_SMOD_project)**: a complex visualization of sound using an artistic approach

<h1 align="center">

  <a href="https://github.com/pasquale90/the_SMOD_project"><img src="https://github.com/pasquale90/the_SMOD_project/raw/main/demo.gif" width="500"></a>

</h1>
